{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the top trending repositories of github\n",
    "\n",
    "Web scraping is the process of extracting and parsing data from websites in an automated fashion using a computer program. It's a useful technique for creating datasets for research and learning. Follow these steps to build a web scraping project from scratch using Python and its ecosystem of libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a website and describe your objective\n",
    "\n",
    "  -  Browse through different sites and pick on to scrape. Check the \"Project Ideas\" section for inspiration.\n",
    "  -  Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "  -  Summarize your project idea and outline your strategy in a Juptyer notebook. Use the \"New\" button above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we are going to use https://github.com/topics\n",
    "- We will scrape the top 20 repositories of some topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the requests library to download web pages\n",
    "\n",
    "  -  Inspect the website's HTML source and identify the right URLs to download.\n",
    "  -  Download and save web pages locally using the requests library.\n",
    "  -  Create a function to automate downloading for different topics/search queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://github.com/topics'\n",
    "r = requests.get(url)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('topics.html', 'w') as page:\n",
    "#     page.write(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Beautiful Soup to parse and extract information\n",
    "\n",
    "  -  Parse and explore the structure of downloaded web pages using Beautiful soup.\n",
    "  -  Use the right properties and methods to extract the required information.\n",
    "  -  Create functions to extract from the page into lists and dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_divs = soup.find_all('div', {'class' : 'py-4'})\n",
    "topic_titles = []\n",
    "topic_urls = []\n",
    "topic_descs = []\n",
    "for div in topic_divs:\n",
    "    link = 'https://github.com' + div.find('a')['href']\n",
    "    topic_urls.append(link)\n",
    "\n",
    "    topic_info = div.find_all('p')\n",
    "\n",
    "    title = topic_info[0].text\n",
    "    topic_titles.append(title)\n",
    "\n",
    "    desc = topic_info[1].text.strip()\n",
    "    topic_descs.append(desc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "    \"title\" : topic_titles.\n",
    "    \"description\" : topic_descs,\n",
    "    \"url\" : topic_urls\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(topics, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
